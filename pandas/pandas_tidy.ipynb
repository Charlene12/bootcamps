{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas: From messy to tidy datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pandas library for Python was build around the dataframe idea taken from R, the statistical programming language. Wes McKinney is the driving force behind the library (O'Reilly book: Python for Data Analysis).\n",
    "\n",
    "Hadley Wickham is his R counterpart working on RStudio, the free programming environment for R, and author of some important R libraries.\n",
    "\n",
    "Hardly any flame wars between the R and Python communities. McKinney and Wickham sometimes work together closely, the fruits of which find their way into both languages. R is real strong in hard core statistical libraries and has a kind of functional twist to it and, at least for me, a bit of a quirky syntax; Python is the more broad programming language with strong support, through its libraries, for scientific programming.\n",
    "\n",
    "Both languages have \"notebooks\", and it is possible in the Jupyter ([JU]lia[PYT]hone[R]) noteboooks to incorporate both Python and R snippets. CSV files are the \"lingua franca\" between the languages.\n",
    "\n",
    "In 2014 Hadley Wickham wrote an important article in the Journal of Statistical Software: \"Tidy Data\".\n",
    "\n",
    "In it he argued for a certain way of structuring data in order to make it more easy and effective to clean and work with the data: Using consistent data structures and matching tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tidy structure has the following attributes:\n",
    "\n",
    "  - Each variable forms a column and contains values\n",
    "  - Each observation forms a row\n",
    "  - Each observational unit forms a table\n",
    "  \n",
    "  where:\n",
    "  \n",
    "  - variable is a measurement or an attribute (height, weight, sex, etc.)\n",
    "  - value is the actual measurement or attribute (152 cm, 80 kg, female, etc.)\n",
    "  - observation: all values measure on the same unit\n",
    "  \n",
    "A dataset that is not tidy is messy.\n",
    "\n",
    "Why are there messy datasets? Well, life is messy in a way. Often datasets get messy because they are used for presentation purposes and values of variables tend to creep into column headers. Or, in order to facilitate the input of data, one stores multiple variables into one column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get some working experience with Pandas we will start to struggle a bit with messy datasets and tidy them up. Later on we will analyze the datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a firmer grasp on the problem, let's look a a very simple, but slightly messy dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we open the file in an editor to have a look at it. A quick repair is to name the missing header.\n",
    "\n",
    "Then we use Pandas to read in the csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./data/treatment.csv\", sep=\";\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column containing name values is not named (has no header); the other two column headers contain values. The 5 or 6 values (depending on how we count the \"-\") in the cells are not given a proper variable name (header), they are just framed by the other values. This lay-out is perfectly ok for presentation purposes, but in order to process the data, we need a clear cut difference between variables and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "melted_df = pd.melt(df,\n",
    "                   [\"Name\"],\n",
    "                   var_name = \"Treatment\",\n",
    "                   value_name = \"Result\")\n",
    "melted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column headers are values, not variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import glob\n",
    "\n",
    "df = pd.read_csv(\"./data/pew-raw.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "formatted_df = pd.melt(df,\n",
    "                      [\"religion\"],\n",
    "                      var_name = \"income\",\n",
    "                      value_name = \"freq\")\n",
    "formatted_df = formatted_df.sort_values(by = [\"religion\"])\n",
    "formatted_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_songs = pd.read_csv(\"./data/billboard.csv\", encoding = \"mac_latin2\")\n",
    "df_songs.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file above has two big drawbacks: Again values in the column headers (x1st.week, etc.) and when a song is in the Top 100 for less then 75 weeks, the remaining columns are filled with missing values (NaN).\n",
    "\n",
    "Now that we know the problems, let's make a plan to fix them:\n",
    "\n",
    "- we will store the week numbers as values in a single column (melt them into a date column)\n",
    "- we will create one row per week for each record (if there is no data for the given week, we will NOT create a row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Note that the first 7 columns of the dataframe are ok\n",
    "# We will store their names in a list\n",
    "id_vars = [\"year\",\n",
    "          \"artist.inverted\",\n",
    "          \"track\",\n",
    "          \"time\",\n",
    "          \"genre\",\n",
    "          \"date.entered\",\n",
    "          \"date.peaked\"]\n",
    "\n",
    "# Now we can start to melt the weeks into a week variable and the ranking number into rank value\n",
    "# All the heavylifting is done by the melt fuction of Pandas\n",
    "df = pd.melt(frame=df_songs,\n",
    "            id_vars = id_vars,\n",
    "            var_name = \"week\",\n",
    "            value_name = \"rank\")\n",
    "# Quick look to see what we did\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The values in the week column can be polished a bit\n",
    "# We just need the number between \"x\"[Int]\"st.week\"\n",
    "# And while we are at it: We can do without the float in the rank column\n",
    "# Formatting to the rescue\n",
    "import re\n",
    "df['week'] = df['week'].str.extract('(\\d+)',expand = False).astype(int)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, bummer; a whopping error. We forgot that our rank column, after the melting, contains all these NaN values and Python complained that it did not know how to convert \"NaN\" into an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's check\n",
    "print(df['rank'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Away with the thing!\" We use the dropna() function on our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df['rank'] = df['rank'].astype(int)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to add values for the new date column\n",
    "We have date.entered values and we have an integer for week\n",
    "With these two values we can compute the values for our new date column\n",
    "With the help of Pandas using the Python datetime library, we:\n",
    "- convert date.entered\n",
    "- convert the week value\n",
    "- add the two up\n",
    "- subtract the offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "pd.to_datetime(\"2009-09-23\")\n",
    "#pd.to_timedelta(1, unit='w')\n",
    "#pd.to_datetime(\"2009-09-23\") + pd.to_timedelta(1, unit='w')\n",
    "#pd.DateOffset(weeks=1)\n",
    "#pd.to_datetime(\"2009-09-23\") + pd.to_timedelta(2, unit='w') - pd.DateOffset(weeks=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In order to populate the new date column, we just have to add the new column\n",
    "df['date'] = pd.to_datetime(df['date.entered']) + pd.to_timedelta(df['week'], unit='w') - pd.DateOffset(weeks=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get a better overview of the rise and fall of records in the chart, we need to sort the dataframe\n",
    "We construct a new dataframe using a nested list of lists; leaving out date.entered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[[\"year\",\n",
    "        \"artist.inverted\",\n",
    "        \"track\",\n",
    "        \"time\",\n",
    "        \"genre\",\n",
    "        \"week\",\n",
    "        \"rank\",\n",
    "        \"date\"]]\n",
    "df = df.sort_values(ascending = True, by = [\"year\", \"artist.inverted\", \"track\", \"week\", \"rank\"])\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have come a long way, but our dataframe is still messy in the sense that in one dataframe or table we combine two observational units: song and rank. Two observational units should be presented in two tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First we store our dataframe in a new variable: billboard\n",
    "billboard = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We then create a songs table that contains the details of each song\n",
    "# First we define the columns for that table:\n",
    "songs_cols = [\"year\",\n",
    "             \"artist.inverted\",\n",
    "             \"track\",\n",
    "             \"time\",\n",
    "             \"genre\"]\n",
    "songs = billboard[songs_cols].drop_duplicates()\n",
    "songs = songs.reset_index(drop = True)\n",
    "songs[\"song_id\"] = songs.index\n",
    "songs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we create a rank table that just contains the newly generated song_id together with date and rank\n",
    "ranks = pd.merge(billboard, songs, on = [\"year\", \"artist.inverted\", \"track\", \"time\", \"genre\"])\n",
    "ranks = ranks[[\"song_id\", \"date\", \"rank\"]]\n",
    "ranks.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
