{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Stream with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If needed\n",
    "# !pip install tweepy\n",
    "# !pip install textblob\n",
    "# !pip install nltk\n",
    "# 2wEURk users, add \"--user\"\n",
    "\n",
    "# If needed\n",
    "# import nltk\n",
    "# nltk.download()  # Select twitter_samples under tab 'Corpora'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports always goes on top\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "from textblob import TextBlob\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "from nltk.corpus import twitter_samples\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Don't want this in GitHub or show on the slides\n",
    "import twitter_credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We'll train a classifier on the NLTK twitter samples\n",
    "# This takes some time, so do only once per session\n",
    "\n",
    "# List of 2-tuples, with each 2-tuple a list of strings and a label  \n",
    "train = []\n",
    "\n",
    "# First the negs\n",
    "for tokens in twitter_samples.tokenized('negative_tweets.json'):\n",
    "    train.append((tokens, 'neg'))\n",
    "    \n",
    "# First the poss\n",
    "for tokens in twitter_samples.tokenized('positive_tweets.json'):\n",
    "    train.append((tokens, 'pos'))\n",
    "\n",
    "# Take a subset, speed up training\n",
    "random.shuffle(train)\n",
    "train = train[0:200]\n",
    "\n",
    "#print(train[0])\n",
    "cl = NaiveBayesClassifier(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Tweet:\n",
    "    \"\"\"This class creates a tweet from a JSON string\"\"\"\n",
    "    def __init__(self, data, cl):\n",
    "        # Hint : print(self._tweet.keys()) for all keys in the tweet\n",
    "        self._tweet = json.loads(data)\n",
    "        self.blob1 = TextBlob(self._tweet[\"text\"], classifier=cl)\n",
    "        self.blob2 = TextBlob(self._tweet[\"text\"], analyzer=NaiveBayesAnalyzer())\n",
    "        \n",
    "    def print_tweet(self):\n",
    "        print()\n",
    "        print(\"-\" * 80)\n",
    "        print(self._tweet[\"id_str\"], self._tweet[\"created_at\"])\n",
    "        print(self._tweet[\"text\"])\n",
    "    \n",
    "    def print_language(self):\n",
    "        print(\"language\", self.blob1.detect_language())\n",
    "        \n",
    "    def print_sentiment(self):\n",
    "        print(\"sentiment\", self.blob1.classify())\n",
    "        print(self.blob2.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyListener(StreamListener):\n",
    "    \"\"\"Listener class that processes a Twitter Stream\"\"\"\n",
    "    def __init__(self, max_count, cl):\n",
    "        self.max_count = max_count\n",
    "        self.count = 0\n",
    "        self.cl = cl\n",
    "    \n",
    "    def on_data(self, data):\n",
    "        self.tweet = Tweet(data, cl)\n",
    "        self.tweet.print_tweet()\n",
    "        self.tweet.print_language()\n",
    "        self.tweet.print_sentiment()\n",
    "                \n",
    "        self.count += 1\n",
    "        if self.count >= self.max_count:\n",
    "            return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the auth object\n",
    "# https://www.slickremix.com/docs/how-to-get-api-keys-and-tokens-for-twitter/\n",
    "auth = OAuthHandler(twitter_credentials.consumer_key, twitter_credentials.consumer_secret)\n",
    "auth.set_access_token(twitter_credentials.access_token, twitter_credentials.access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a listener, define max tweets we'll process, pass the classifier\n",
    "mylistener = MyListener(10, cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a stream, and use the listener to process the data\n",
    "mystream = Stream(auth, listener=mylistener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a list of keywords to search the Tweets\n",
    "keywords = ['Python', 'Jupyter', 'eur.nl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Start the stream, based on the keyword-list\n",
    "mystream.filter(track = keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Disconnects the streaming data\n",
    "mystream.disconnect()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
