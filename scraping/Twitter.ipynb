{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Stream with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If needed\n",
    "#!pip install tweepy\n",
    "#!pip install textblob\n",
    "#!pip install nltk\n",
    "# 2wEURk users, add \"--user\"\n",
    "\n",
    "# If needed\n",
    "#!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "from textblob import TextBlob\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "from nltk.corpus import twitter_samples\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Don't want this in GitHub\n",
    "import twitter_credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating authentication keys\n",
    "auth = OAuthHandler(twitter_credentials.consumer_key, twitter_credentials.consumer_secret)\n",
    "auth.set_access_token(twitter_credentials.access_token, twitter_credentials.access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "\n",
    "# First the negs\n",
    "for tokens in twitter_samples.tokenized('negative_tweets.json'):\n",
    "    train.append((tokens, 'neg'))\n",
    "    \n",
    "# First the poss\n",
    "for tokens in twitter_samples.tokenized('positive_tweets.json'):\n",
    "    train.append((tokens, 'pos'))\n",
    "\n",
    "random.shuffle(train)\n",
    "train = train[0:100]\n",
    "cl = NaiveBayesClassifier(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tweet:\n",
    "    def __init__(self, data, cl):\n",
    "        # Hint : print(self._tweet.keys()) for all keys in the tweet\n",
    "        self._tweet = json.loads(data)\n",
    "        self.blob1 = TextBlob(self._tweet[\"text\"], classifier=cl)\n",
    "        self.blob2 = TextBlob(self._tweet[\"text\"], analyzer=NaiveBayesAnalyzer())\n",
    "        \n",
    "    def print_tweet(self):\n",
    "        print()\n",
    "        print(self._tweet[\"id_str\"], self._tweet[\"created_at\"])\n",
    "        print(self._tweet[\"text\"])\n",
    "    \n",
    "    def print_language(self):\n",
    "        print(\"language\", self.blob1.detect_language())\n",
    "        \n",
    "    def print_sentiment(self):\n",
    "        print(\"sentiment\", self.blob1.classify())\n",
    "        print(self.blob2.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyListener(StreamListener):\n",
    "    def __init__(self, max_count, cl):\n",
    "        self.max_count = max_count\n",
    "        self.count = 0\n",
    "        self.cl = cl\n",
    "    \n",
    "    def on_data(self, data):\n",
    "        self.tweet = Tweet(data, cl)\n",
    "        self.tweet.print_tweet()\n",
    "        self.tweet.print_language()\n",
    "        self.tweet.print_sentiment()\n",
    "                \n",
    "        self.count += 1\n",
    "        if self.count >= self.max_count:\n",
    "            return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a listener, define max tweets we'll process\n",
    "mylistener = MyListener(10, cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mystream = Stream(auth, listener=mylistener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a list of keywords to search the Tweets\n",
    "keywords = ['Python', 'Jupyter', 'eur.nl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "857002738118348801 Tue Apr 25 22:45:49 +0000 2017\n",
      "@herufeanor Isn't there a Monty Python skit about fracturing socialist revolutionaries?\n",
      "language en\n",
      "sentiment neg\n",
      "Sentiment(classification='pos', p_pos=0.899232237392307, p_neg=0.10076776260769248)\n",
      "\n",
      "857002743860514816 Tue Apr 25 22:45:51 +0000 2017\n",
      "BMW Group  will start Reasearch in the Role...  #javascript #Python https://t.co/wSo25BUbKc\n",
      "language en\n",
      "sentiment pos\n",
      "Sentiment(classification='neg', p_pos=0.4600880582754997, p_neg=0.5399119417244997)\n",
      "\n",
      "857002784192962562 Tue Apr 25 22:46:00 +0000 2017\n",
      "RT @DD_NaNa_: 5,993+ Enrolled Deep Learning Prerequisites: Logistic Regression in #Python https://t.co/caOMN5hMK8\n",
      "language en\n",
      "sentiment pos\n",
      "Sentiment(classification='pos', p_pos=0.504249181350383, p_neg=0.49575081864961823)\n",
      "\n",
      "857002789691682816 Tue Apr 25 22:46:02 +0000 2017\n",
      "@AutomaticWickie @Dr_Draper Slightly reminds me of the Python \"Four Yorkshiremen\" sketch - \"I used to wake up half… https://t.co/qJqIyRQcIk\n",
      "language en\n",
      "sentiment pos\n",
      "Sentiment(classification='pos', p_pos=0.581462973493816, p_neg=0.4185370265061844)\n",
      "\n",
      "857002793244164100 Tue Apr 25 22:46:02 +0000 2017\n",
      "RT @DD_NaNa_: Applied Data Science with Python https://t.co/fCktzzlFo3 #datascience\n",
      "language en\n",
      "sentiment pos\n",
      "Sentiment(classification='neg', p_pos=0.4735896090694063, p_neg=0.526410390930593)\n",
      "\n",
      "857002813959749632 Tue Apr 25 22:46:07 +0000 2017\n",
      "【はてブ新着IT】 Selenium WebDriver + python で E2Eテスト自動化 https://t.co/yrH5YdS8T9\n",
      "language ja\n",
      "sentiment pos\n",
      "Sentiment(classification='pos', p_pos=0.5416666666666665, p_neg=0.45833333333333337)\n",
      "\n",
      "857002865184784384 Tue Apr 25 22:46:20 +0000 2017\n",
      "えとをしらべるプログラム。。#Python #プログラミング初心者 https://t.co/9uysayRM2r\n",
      "language ja\n",
      "sentiment pos\n",
      "Sentiment(classification='pos', p_pos=0.5416666666666665, p_neg=0.45833333333333337)\n",
      "\n",
      "857002870088114176 Tue Apr 25 22:46:21 +0000 2017\n",
      "Tiempo Development: Win a trip to #Huatulco for 2! Send us your #Python Tech Lead referral to referrals@tiempod... https://t.co/8S40WO3ViJ\n",
      "language en\n",
      "sentiment pos\n",
      "Sentiment(classification='pos', p_pos=0.6410713855366659, p_neg=0.35892861446333324)\n",
      "\n",
      "857002899217408000 Tue Apr 25 22:46:28 +0000 2017\n",
      "RT @KirkDBorne: R and #Python cheatsheets for #DataScientists: https://t.co/1uZN8FgNL9 #abdsc #BigData #DataScience #Rstats… \n",
      "language en\n",
      "sentiment pos\n",
      "Sentiment(classification='pos', p_pos=0.5442475959455946, p_neg=0.45575240405440526)\n",
      "\n",
      "857002911037091840 Tue Apr 25 22:46:30 +0000 2017\n",
      "RT @DesignDarren: Machine Learning A-Z™: Hands-On Python &amp; R In Data Science  ☞ https://t.co/y7NG1qdnB5 https://t.co/wbYIdKRnlf\n",
      "language en\n",
      "sentiment pos\n",
      "Sentiment(classification='pos', p_pos=0.5300440283266592, p_neg=0.4699559716733415)\n"
     ]
    }
   ],
   "source": [
    "mystream.filter(track = keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Disconnects the streaming data\n",
    "mystream.disconnect()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
