{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanic\n",
    "\n",
    "There are 3 contexts here:\n",
    "   \n",
    "    - Jupyter notebooks. We touched upon this during the introduction. Kind of a playground, especially suited for computing with data, because one is able to bring together data, code and results (visualisations) in one environment, the notebooks.\n",
    "    - so-called \"Big Data\" and data analysis with computers present new possibilities for economic and econometric practice and research.\n",
    "    - and there is the context of the data we are going to work with: The Titanic disaster. There are various technical ways to look at it. Below there is a link to a computer generated simulation of the actual sinking of the Titanic made by the team of James Cameron.\n",
    "    \n",
    "<a href=\"https://www.youtube.com/watch?v=FSGeskFzE0s\">James Cameron: How the Titanic sank</a>\n",
    "\n",
    "We are going to look at the data about the persons on board with the help of the computer an Python as our programming environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### What do we know already?\n",
    "\n",
    "You probably have seen the movie Titanic (with Kate Winslet and Leonardo DiCaprio, 1997), one of several movies made about the disaster. So you probably know the following:\n",
    "\n",
    "    - The disaster took place during the night of April 14, 1912 when the ship hit an iceberg\n",
    "      on her maiden voyage from Southampton (UK) to New York (US) via Cherbourg (FR) and Queenstown (IRE).\n",
    "    - The loss of lives was 1501 (out of a total of 2207) passengers;\n",
    "    - There was a shortage of life-boats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do we want to know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It might well be you have some questions in advance and want to use the data to see if you can find answers, or it could well be you want to play a little bit with the data in order to come up with questions.\n",
    "\n",
    "Both approaches suggest the following steps:\n",
    "\n",
    "    - Explore the data (load it, look at it)\n",
    "    - Clean the data (missing values, splitting columns, etc.)\n",
    "    - Plot (try to visualize correlations, insights, ...)\n",
    "    - Assumptions (try to formulate hypotheses, rinse and repeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data\n",
    "\n",
    "Mind you we are cheating big time here! We start with existing datasets that allow us to quickly load and explore data, as we will see shortly. Suppose you are a data scientist out in the wild, you will probably get assignments *without* any accompanying datasets. A large proportion of your time will be spend on acquiring data (searching, scraping), cleaning data, combining data from various sources (a lot of tweaking and cleaning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Set up an environment to be able to explore the data\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "#pd.options.display.max_columns = 100\n",
    "#pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we have a csv file here, that is a plain text file with each chunk of information separated by a comma, hence csv or \"comma separated value\" file, we can open up the file in a text editor and look at the contents of our source file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!aquamacs /Users/peter/Documents/bootcamps/data/titanic/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/titanic/train.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data in a dataframe (a matrix with columns, variables, that contain various datatypes), we can have quick different looks at the contents using several methods of the dataframe object:\n",
    "\n",
    "    - head (what is there? shows first five rows of the dataset with the header values if any)\n",
    "    - info (how many total entries? what are the columns and their types? how many not-null values per column)\n",
    "    - describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/titanic/test.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can select the values of columns using iloc() and the column number (counting from 0)\n",
    "df_train.iloc[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This typical notation with the \"dangling comma\" is a reminder of the provenance of the Pandas library: R dataframes. Where ,1 denotes a column and 1, denotes a row.\n",
    "Hence the following use of the iloc() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[:1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And because iloc[:,1] returns the is the survived column, we can use the label together with the loc() method:\n",
    "df_train.loc[:,'Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can slice columns, through the similar kind of subscription we saw when working with lists\n",
    "# For example, we take the first 10 values of the column survived\n",
    "# We have the column names as methods in the dataframe object: df.survived[0:10] also works\n",
    "df_train['Survived'][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the contents of the survived column are floats, which is true, but they actually function as Boolean types: True (1.0) and False (0.0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the simple fact that not many people survived (df.info gives us the number of 486 people registered as survivors? in boats on a total of 1309 passengers = 37% survived?). Who did actually survive and are there relations with age, sex, and travel class?\n",
    "\n",
    "We can prepare quick sneak previews with slicing data using several columns (note1: we have to pass the columns we are interested in in as a list; note2: selecting the first ten passengers we are looking at first class passengers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_train[['Survived','Age','Sex','Pclass']][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a quick look at the third class. We can use the opposite of the head command (which is aptly called \"tail\") or we can use a negative slice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[['Survived','Age','Sex','Pclass']][-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right, we might have something here. Let's get to work.\n",
    "\n",
    "Correlations: Let's focus on survived in relation to: sex, age, class\n",
    "Completions: We miss age data (1046 non-null data points) and we might want to factorize this column\n",
    "Corrections: We might want to drop certain columns, because we are not going to use them for our initial analysis: ticket, cabin, passengerId.\n",
    "\n",
    "From here we can choose several paths to explore the data a bit more. For example use the crosstab method of a dataframe to make a cross tabulation on gender and survival:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df_train.Sex, df_train.Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to do a quick crosstab between survived and age, but this, of course, blows up: To do something sensible with age, we need to clean it up and \"factorize\" it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df_train.Age, df_train.Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the method unique() to get hold of unique values within a column:\n",
    "df_train.Embarked.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the beginning we loaded a test set. At random selection from the file \"Titanic3.csv\", or to be more precise we divided the file into a training set and a test set. What can we learn from the training set in order to predict the survival of the persons from the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a column to the test df and fill in with all zeros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a new dataframe of two columns: PassengerId, Survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write that selection to a file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected bibliography\n",
    "\n",
    "#### About the RMS Titanic\n",
    "\n",
    "- Encyclopedia Titanica. Titanic Facts, History and Biography: https://www.encyclopedia-titanica.org/\n",
    "\n",
    "#### Economics, Machine Learning, and the Titanic\n",
    "\n",
    "- Bruno S. Frey, David A. Savage, and Benno Torgler, Behavior under Extreme Conditions: The Titanic Disaster, in: Journal of Economic Perspectives, vol. 25, number 1, Winter 2011, pp. 209-222, DOI: http://dx.doi.org/10.1257/jep.25.1.209\n",
    "\n",
    "- Hal R. Varian, Big Data: New Tricks for Econometrics, in: Journal of Economic Perspectives, vol. 28, number 2, Spring 2014, pp. 3-28 (Titanic, pp. 7-12), DOI: http://dx.doi.org/10.1257/jep.28.2.3\n",
    "\n",
    "- Sendhil Mullainathan and Jann Spiess, Machine Learning: An Applied Econometric Approach, in: Journal of Economic Perspectives, vol. 31, number 2, Spring 2017, pp. 87-106, DOI: http://dx.doi.org/10.1257/jep.31.2.87\n",
    "\n",
    "- Francis X. Diebold, All of Machine Learning in One Expression, retrieved from the blog \"No Hesitations\" (posted: Monday, January 9, 2017) on 20-09-2017 at: https://fxdiebold.blogspot.nl/2017/01/all-of-machine-learning-in-one.html\n",
    "\n",
    "#### Statistics and computing (R programming language)\n",
    "\n",
    "- Trevor Hastie, Robert Tibshirani, and J. Friedman, Elements of Statistical Learning, 2nd ed., New York, Springer Science and Business Media, 2009, http://statweb.stanford.edu/~tibs/ElemStatLearn/\n",
    "\n",
    "- Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani, An Introduction to Statistical Learning with Applications in R, New York, Springer Science and Business Media, 2013, http://www-bcf.usc.edu/~gareth/ISL/index.html Python code for some chapters of the book can be found here: https://github.com/JWarmenhoven/ISLR-python)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
